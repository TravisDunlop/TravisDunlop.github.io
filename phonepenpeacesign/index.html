<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <link rel="stylesheet" href="style.css">
    <title>Phone, Pen, or Peace?</title>


</head>
<body>
<div class = 'content'>
  <h1>phone, pen, or peace sign?</h1>

  This webpage can classify things placed in front of the camera as a phone, a pen, or a peace sign!
  First you need teach the machine what each of these look like.  Hold your phone up to the camera and press the
  button to the bottom left.  It will collect picture training examples of your phone so it learns what it looks like.
  Then do the same thing with a pen, and finally with your hand in a peace sign. Collect about 20-30 examples for each class.

  Now, put any one of these objects in front of the camera and text will appear below classifying it!  Enjoy!

  <script src="dist/build.js"></script>

  This project was really fast to implement thanks to <a href=''>teachable-machine-boilerplate</a> from Google.
  It was a fun introduction to using deeplearn.js, the web frame work for implementing deep learning models.

  Q&A:
  - Are you collecting my video?
    No, all computation happens in your browser!
  - I thought deep learning required big data? How does it work off of only 20-30 examples?
    The way this works is by first using a really general image classifier trained on a thousand classes.
    This net was trained really well

</div>
</body>
</html>
